{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0b19bf9",
        "outputId": "69c70a11-3e54-45a7-e8ab-868089fb0d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "Features (X) shape: (150, 4)\n",
            "Target (y) shape: (150,)\n",
            "First 5 rows of features (X):\n",
            "    sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.1          3.5           1.4          0.2\n",
            "1           4.9          3.0           1.4          0.2\n",
            "2           4.7          3.2           1.3          0.2\n",
            "3           4.6          3.1           1.5          0.2\n",
            "4           5.0          3.6           1.4          0.2\n",
            "First 5 encoded target values (y):\n",
            " [0 0 0 0 0]\n",
            "Original species labels (first 5):\n",
            " 0    setosa\n",
            "1    setosa\n",
            "2    setosa\n",
            "3    setosa\n",
            "4    setosa\n",
            "Name: species, dtype: object\n",
            "Encoded target classes: ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"SCOA_A4.csv\")\n",
        "\n",
        "# Identify feature and target columns\n",
        "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "y_categorical = df['species']\n",
        "\n",
        "# Encode the target column\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_categorical)\n",
        "\n",
        "print(\"Dataset loaded successfully.\")\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "print(\"First 5 rows of features (X):\\n\", X.head())\n",
        "print(\"First 5 encoded target values (y):\\n\", y[:5])\n",
        "print(\"Original species labels (first 5):\\n\", y_categorical[:5])\n",
        "print(\"Encoded target classes:\", le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97094c90",
        "outputId": "7a18eaa8-7c51-44d7-d17a-6bb98cee75e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Genetic Algorithm...\n",
            "Generation 1/10 - Best Fitness: 0.9733\n",
            "Generation 2/10 - Best Fitness: 0.9733\n",
            "Generation 3/10 - Best Fitness: 0.9733\n",
            "Generation 4/10 - Best Fitness: 0.9733\n",
            "Generation 5/10 - Best Fitness: 0.9733\n",
            "Generation 6/10 - Best Fitness: 0.9733\n",
            "Generation 7/10 - Best Fitness: 0.9733\n",
            "Generation 8/10 - Best Fitness: 0.9733\n",
            "Generation 9/10 - Best Fitness: 0.9733\n",
            "Generation 10/10 - Best Fitness: 0.9733\n",
            "\n",
            "Genetic Algorithm Finished.\n",
            "Best Hyperparameters: max_depth=3, min_samples_split=7\n",
            "Best Accuracy: 0.9733\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# --- Genetic Algorithm Setup ---\n",
        "POP_SIZE = 20      # number of individuals\n",
        "N_GENERATIONS = 10 # iterations\n",
        "MUTATION_RATE = 0.2\n",
        "\n",
        "# Chromosome: [max_depth, min_samples_split]\n",
        "def create_chromosome():\n",
        "    return [random.randint(1, 20), random.randint(2, 10)]\n",
        "\n",
        "def fitness(chromosome):\n",
        "    max_depth, min_samples_split = chromosome\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split,\n",
        "                                   random_state=42) # Added random_state for reproducibility\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    return scores.mean()\n",
        "\n",
        "def selection(population, fitnesses):\n",
        "    # Select the best two individuals for crossover\n",
        "    idx = np.argsort(fitnesses)[-2:]\n",
        "    return [population[idx[0]], population[idx[1]]]\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    # Perform single-point crossover\n",
        "    point = random.randint(0, len(parent1)-1)\n",
        "    child1 = parent1[:point] + parent2[point:]\n",
        "    child2 = parent2[:point] + parent1[point:]\n",
        "    return child1, child2\n",
        "\n",
        "def mutate(chromosome):\n",
        "    # Apply mutation to max_depth\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[0] = random.randint(1, 20)\n",
        "    # Apply mutation to min_samples_split\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[1] = random.randint(2, 10)\n",
        "    return chromosome\n",
        "\n",
        "# --- Run GA ---\n",
        "population = [create_chromosome() for _ in range(POP_SIZE)]\n",
        "\n",
        "print(\"Starting Genetic Algorithm...\")\n",
        "for gen in range(N_GENERATIONS):\n",
        "    fitnesses = [fitness(chromo) for chromo in population]\n",
        "    print(f\"Generation {gen+1}/{N_GENERATIONS} - Best Fitness: {max(fitnesses):.4f}\")\n",
        "\n",
        "    new_population = []\n",
        "    parents = selection(population, fitnesses)\n",
        "\n",
        "    # Generate new population through crossover and mutation\n",
        "    for _ in range(POP_SIZE // 2):\n",
        "        child1, child2 = crossover(parents[0], parents[1])\n",
        "        new_population.append(mutate(child1))\n",
        "        new_population.append(mutate(child2))\n",
        "\n",
        "    population = new_population\n",
        "\n",
        "# Best result from the final population\n",
        "fitnesses = [fitness(chromo) for chromo in population]\n",
        "best_idx = np.argmax(fitnesses)\n",
        "best_hyperparameters = population[best_idx]\n",
        "best_accuracy = fitnesses[best_idx]\n",
        "\n",
        "print(\"\\nGenetic Algorithm Finished.\")\n",
        "print(f\"Best Hyperparameters: max_depth={best_hyperparameters[0]}, min_samples_split={best_hyperparameters[1]}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Below is a clear and viva-ready explanation covering:\n",
        "\n",
        "* Meaning & significance of the code\n",
        "* Implementation steps\n",
        "* Interpretation of output\n",
        "* Key viva questions with short answers\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ **Objective of the Code**\n",
        "\n",
        "The goal of this code is to **automatically find the best hyperparameters** (`max_depth`, `min_samples_split`) for a **Decision Tree Classifier** using a **Genetic Algorithm (GA)** â€” instead of manually tuning them.\n",
        "\n",
        "* **Dataset Used:** Iris dataset (`SCOA_A4.csv`)\n",
        "* **Algorithm Used:** Genetic Algorithm (GA)\n",
        "* **Model Tuned:** Decision Tree Classifier\n",
        "* **Evaluation Metric:** Mean Accuracy (via 5-fold Cross-Validation)\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ **Step-by-Step Explanation**\n",
        "\n",
        "### **1ï¸âƒ£ Data Loading and Encoding**\n",
        "\n",
        "```python\n",
        "df = pd.read_csv(\"SCOA_A4.csv\")\n",
        "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "y_categorical = df['species']\n",
        "```\n",
        "\n",
        "* **Features (X):** Numerical measurements of Iris flowers.\n",
        "* **Target (y):** Flower species â€” categorical labels: `setosa`, `versicolor`, `virginica`.\n",
        "\n",
        "Encoding:\n",
        "\n",
        "```python\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_categorical)\n",
        "```\n",
        "\n",
        "* Converts species names into numeric form:\n",
        "  `setosa â†’ 0`, `versicolor â†’ 1`, `virginica â†’ 2`.\n",
        "\n",
        "âœ… **Purpose:** Machine learning models require numerical target values.\n",
        "\n",
        "---\n",
        "\n",
        "### **2ï¸âƒ£ GA Setup**\n",
        "\n",
        "```python\n",
        "POP_SIZE = 20      # number of individuals (candidate solutions)\n",
        "N_GENERATIONS = 10 # number of iterations\n",
        "MUTATION_RATE = 0.2\n",
        "```\n",
        "\n",
        "Each individual (chromosome) represents a set of hyperparameters:\n",
        "\n",
        "```python\n",
        "[max_depth, min_samples_split]\n",
        "```\n",
        "\n",
        "* `max_depth`: how deep the tree can grow\n",
        "* `min_samples_split`: minimum samples required to split a node\n",
        "\n",
        "Both affect **model complexity and accuracy**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3ï¸âƒ£ Creating Initial Population**\n",
        "\n",
        "```python\n",
        "def create_chromosome():\n",
        "    return [random.randint(1, 20), random.randint(2, 10)]\n",
        "```\n",
        "\n",
        "* Generates random hyperparameter values for the first generation.\n",
        "\n",
        "---\n",
        "\n",
        "### **4ï¸âƒ£ Fitness Function**\n",
        "\n",
        "```python\n",
        "def fitness(chromosome):\n",
        "    max_depth, min_samples_split = chromosome\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    return scores.mean()\n",
        "```\n",
        "\n",
        "* Each individual is evaluated by training a Decision Tree using its parameters.\n",
        "* The **fitness** is the **average cross-validation accuracy**.\n",
        "* Higher fitness = better model performance.\n",
        "\n",
        "âœ… **Goal:** Maximize accuracy â†’ find the chromosome with best fitness.\n",
        "\n",
        "---\n",
        "\n",
        "### **5ï¸âƒ£ Selection**\n",
        "\n",
        "```python\n",
        "def selection(population, fitnesses):\n",
        "    idx = np.argsort(fitnesses)[-2:]\n",
        "    return [population[idx[0]], population[idx[1]]]\n",
        "```\n",
        "\n",
        "* Selects **two best chromosomes** (parents) with highest fitness.\n",
        "* These will produce the next generation through crossover.\n",
        "\n",
        "---\n",
        "\n",
        "### **6ï¸âƒ£ Crossover**\n",
        "\n",
        "```python\n",
        "def crossover(parent1, parent2):\n",
        "    point = random.randint(0, len(parent1)-1)\n",
        "    child1 = parent1[:point] + parent2[point:]\n",
        "    child2 = parent2[:point] + parent1[point:]\n",
        "```\n",
        "\n",
        "* Combines parts of two parents to form two new children.\n",
        "* Mimics **biological reproduction**, encouraging good traits to mix.\n",
        "\n",
        "Example:\n",
        "Parent1 = [10, 5], Parent2 = [15, 3] â†’ Crossover â†’ Child1 = [10, 3], Child2 = [15, 5].\n",
        "\n",
        "---\n",
        "\n",
        "### **7ï¸âƒ£ Mutation**\n",
        "\n",
        "```python\n",
        "def mutate(chromosome):\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[0] = random.randint(1, 20)\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[1] = random.randint(2, 10)\n",
        "    return chromosome\n",
        "```\n",
        "\n",
        "* Randomly alters genes (hyperparameters) with some probability.\n",
        "* Keeps diversity in population â†’ avoids local optima.\n",
        "\n",
        "---\n",
        "\n",
        "### **8ï¸âƒ£ Evolution Loop**\n",
        "\n",
        "```python\n",
        "for gen in range(N_GENERATIONS):\n",
        "    fitnesses = [fitness(chromo) for chromo in population]\n",
        "    print(f\"Generation {gen+1}/{N_GENERATIONS} - Best Fitness: {max(fitnesses):.4f}\")\n",
        "```\n",
        "\n",
        "At each generation:\n",
        "\n",
        "1. Evaluate fitness of all individuals.\n",
        "2. Select top parents.\n",
        "3. Create new generation via crossover & mutation.\n",
        "4. Replace old population with new one.\n",
        "\n",
        "This process repeats for 10 generations.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š **Output Interpretation**\n",
        "\n",
        "### **Part 1: Dataset Info**\n",
        "\n",
        "```\n",
        "Features (X) shape: (150, 4)\n",
        "Target (y) shape: (150,)\n",
        "Encoded target classes: ['setosa' 'versicolor' 'virginica']\n",
        "```\n",
        "\n",
        "* Confirms that dataset has 150 samples, 4 features, and 3 classes.\n",
        "\n",
        "---\n",
        "\n",
        "### **Part 2: GA Progress**\n",
        "\n",
        "```\n",
        "Generation 1/10 - Best Fitness: 0.9733\n",
        "...\n",
        "Generation 10/10 - Best Fitness: 0.9733\n",
        "```\n",
        "\n",
        "* Best accuracy (fitness) stabilizes early, meaning optimal hyperparameters are found quickly.\n",
        "\n",
        "---\n",
        "\n",
        "### **Part 3: Final Results**\n",
        "\n",
        "```\n",
        "Best Hyperparameters: max_depth=3, min_samples_split=7\n",
        "Best Accuracy: 0.9733\n",
        "```\n",
        "\n",
        "âœ… **Interpretation:**\n",
        "\n",
        "* Decision Tree with **depth = 3** and **min_samples_split = 7** achieves **97.33% accuracy** (cross-validated).\n",
        "* Indicates an excellent fit â€” model is accurate and not overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© **Significance of GA in this Implementation**\n",
        "\n",
        "| Aspect                         | Explanation                                                                  |\n",
        "| ------------------------------ | ---------------------------------------------------------------------------- |\n",
        "| **Purpose**                    | Automate hyperparameter tuning                                               |\n",
        "| **Approach**                   | Use population-based stochastic optimization                                 |\n",
        "| **Why GA?**                    | It explores a wide search space and can escape local minima                  |\n",
        "| **Advantage over Grid Search** | Fewer evaluations, faster convergence, and flexible parameter representation |\n",
        "| **Result**                     | Finds near-optimal Decision Tree parameters yielding high accuracy           |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—£ï¸ **Viva Quick Answers**\n",
        "\n",
        "**Q1. What is being optimized in this code?**\n",
        "â†’ The hyperparameters `max_depth` and `min_samples_split` of a Decision Tree.\n",
        "\n",
        "**Q2. What does the fitness function represent?**\n",
        "â†’ The 5-fold cross-validation accuracy of the Decision Tree.\n",
        "\n",
        "**Q3. What are the roles of crossover and mutation?**\n",
        "â†’ Crossover mixes good traits from two parents; mutation introduces randomness to maintain diversity.\n",
        "\n",
        "**Q4. Why use Genetic Algorithm for tuning?**\n",
        "â†’ Because GA performs global search and can find optimal parameters efficiently without exhaustive search.\n",
        "\n",
        "**Q5. What is the stopping criterion here?**\n",
        "â†’ The GA stops after a fixed number of generations (`N_GENERATIONS = 10`).\n",
        "\n",
        "**Q6. What is the final modelâ€™s performance?**\n",
        "â†’ ~97.33% accuracy with optimal parameters (max_depth=3, min_samples_split=7).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® **Summary Table**\n",
        "\n",
        "| Step | Description                                            |\n",
        "| ---- | ------------------------------------------------------ |\n",
        "| 1ï¸âƒ£  | Load and encode the Iris dataset                       |\n",
        "| 2ï¸âƒ£  | Define Decision Tree hyperparameters as chromosomes    |\n",
        "| 3ï¸âƒ£  | Evaluate fitness via 5-fold accuracy                   |\n",
        "| 4ï¸âƒ£  | Select best parents based on fitness                   |\n",
        "| 5ï¸âƒ£  | Apply crossover and mutation to create next generation |\n",
        "| 6ï¸âƒ£  | Repeat for 10 generations                              |\n",
        "| 7ï¸âƒ£  | Output best hyperparameters and accuracy               |\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "---\n",
        "\n",
        "## ðŸ§  1. Conceptual Overview\n",
        "\n",
        "**Genetic Algorithm (GA)** is a **stochastic optimization** technique inspired by **Charles Darwinâ€™s theory of natural evolution**.\n",
        "It mimics how biological organisms evolve over generations through **selection**, **crossover**, and **mutation**.\n",
        "\n",
        "GA is widely used for optimization problems where:\n",
        "\n",
        "* The **search space is large or complex** (non-linear, multi-modal, non-differentiable).\n",
        "* **Gradient-based methods** (like in deep learning) are not applicable.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§¬ 2. Core Biological Analogy\n",
        "\n",
        "| Biological Process | GA Equivalent                | Meaning                                    |\n",
        "| ------------------ | ---------------------------- | ------------------------------------------ |\n",
        "| Population         | Set of candidate solutions   | Each candidate = one possible solution     |\n",
        "| Chromosome         | Encoded form of a solution   | E.g., [max_depth, min_samples_split]       |\n",
        "| Gene               | One part of a chromosome     | E.g., max_depth = 5                        |\n",
        "| Fitness            | Quality measure              | How good the solution is                   |\n",
        "| Selection          | Choosing fittest individuals | For reproduction                           |\n",
        "| Crossover          | Combining parent genes       | Produces new offspring (solutions)         |\n",
        "| Mutation           | Random change in genes       | Introduces diversity to avoid local minima |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© 3. Step-by-Step Working Mechanism\n",
        "\n",
        "Letâ€™s link the GA steps to your code and theory.\n",
        "\n",
        "### **Step 1 â€” Initialization**\n",
        "\n",
        "Generate an initial random population of `POP_SIZE` chromosomes.\n",
        "\n",
        "[\n",
        "P^{(0)} = { x_1, x_2, \\dots, x_N }\n",
        "]\n",
        "\n",
        "Each chromosome encodes a possible set of hyperparameters.\n",
        "\n",
        "In your case:\n",
        "\n",
        "```python\n",
        "def create_chromosome():\n",
        "    return [random.randint(1, 20), random.randint(2, 10)]\n",
        "```\n",
        "\n",
        "ðŸ‘‰ Each chromosome = `[max_depth, min_samples_split]`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2 â€” Fitness Evaluation**\n",
        "\n",
        "Each chromosomeâ€™s **fitness** measures how well it solves the problem.\n",
        "\n",
        "[\n",
        "f(x_i) = \\text{performance of the model with parameters } x_i\n",
        "]\n",
        "\n",
        "In your case:\n",
        "\n",
        "```python\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "return scores.mean()\n",
        "```\n",
        "\n",
        "â†’ Fitness = **average accuracy** from 5-fold cross-validation.\n",
        "\n",
        "Mathematically:\n",
        "[\n",
        "f(x_i) = \\frac{1}{k} \\sum_{j=1}^{k} \\text{Accuracy}_j\n",
        "]\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3 â€” Selection**\n",
        "\n",
        "Choose the **best-performing individuals** (highest fitness) to reproduce.\n",
        "\n",
        "Your code:\n",
        "\n",
        "```python\n",
        "idx = np.argsort(fitnesses)[-2:]\n",
        "return [population[idx[0]], population[idx[1]]]\n",
        "```\n",
        "\n",
        "Mathematically, this simulates **â€œsurvival of the fittestâ€**:\n",
        "[\n",
        "P_{\\text{selected}} = \\text{argmax}_{x_i \\in P^{(t)}} f(x_i)\n",
        "]\n",
        "\n",
        "Other popular selection methods:\n",
        "\n",
        "* **Roulette Wheel Selection:** Probability proportional to fitness\n",
        "  ( P(x_i) = \\frac{f(x_i)}{\\sum_j f(x_j)} )\n",
        "* **Tournament Selection:** Pick the best among a random group.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 4 â€” Crossover (Recombination)**\n",
        "\n",
        "Parents combine their genes to form new offspring.\n",
        "\n",
        "Your code:\n",
        "\n",
        "```python\n",
        "point = random.randint(0, len(parent1)-1)\n",
        "child1 = parent1[:point] + parent2[point:]\n",
        "child2 = parent2[:point] + parent1[point:]\n",
        "```\n",
        "\n",
        "Mathematically, for two parents ( x_1, x_2 ):\n",
        "[\n",
        "\\text{child}_1 = (x_1[:c], x_2[c:])\n",
        "]\n",
        "[\n",
        "\\text{child}_2 = (x_2[:c], x_1[c:])\n",
        "]\n",
        "where ( c ) = crossover point.\n",
        "\n",
        "This creates **genetic diversity** by blending two good solutions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 5 â€” Mutation**\n",
        "\n",
        "Randomly change some genes to maintain exploration and avoid premature convergence.\n",
        "\n",
        "Your code:\n",
        "\n",
        "```python\n",
        "if random.random() < MUTATION_RATE:\n",
        "    chromosome[0] = random.randint(1, 20)\n",
        "```\n",
        "\n",
        "Mathematically, for each gene ( g ):\n",
        "[\n",
        "g' =\n",
        "\\begin{cases}\n",
        "\\text{random value}, & \\text{if } r < p_m \\\n",
        "g, & \\text{otherwise}\n",
        "\\end{cases}\n",
        "]\n",
        "\n",
        "where ( p_m ) is the mutation probability (e.g., 0.2).\n",
        "\n",
        "Mutation ensures the algorithm **doesnâ€™t get stuck** in a local optimum.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 6 â€” Replacement**\n",
        "\n",
        "Replace the old population with the newly created offspring:\n",
        "[\n",
        "P^{(t+1)} = \\text{offspring from } P^{(t)}\n",
        "]\n",
        "\n",
        "This iterative process continues for `N_GENERATIONS`.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® 4. Mathematical Foundation (Optimization View)\n",
        "\n",
        "The GA can be viewed as a **stochastic optimization process** over the search space ( S ), trying to maximize a fitness function ( f: S \\rightarrow \\mathbb{R} ).\n",
        "\n",
        "### Objective:\n",
        "\n",
        "[\n",
        "\\max_{x \\in S} f(x)\n",
        "]\n",
        "\n",
        "GA performs **randomized search** guided by fitness proportionate selection.\n",
        "\n",
        "The population evolution can be expressed as a **Markov process**:\n",
        "[\n",
        "P^{(t+1)} = M(P^{(t)})\n",
        "]\n",
        "where ( M ) is a stochastic transformation determined by selection, crossover, and mutation.\n",
        "\n",
        "Over iterations:\n",
        "[\n",
        "\\lim_{t \\to \\infty} \\mathbb{E}[f(P^{(t)})] \\to f^*\n",
        "]\n",
        "(meaning the expected best fitness approaches the global optimum).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© 5. Genetic Algorithm Pseudocode (Mathematical Form)\n",
        "\n",
        "```\n",
        "1. Initialize P(0) = {x1, x2, ..., xN} randomly\n",
        "2. Evaluate f(xi) for all xi âˆˆ P(0)\n",
        "3. Repeat until termination condition:\n",
        "      a. Select parents from P(t)\n",
        "      b. Perform crossover to produce offspring\n",
        "      c. Apply mutation to offspring\n",
        "      d. Form P(t+1) from offspring\n",
        "      e. Evaluate fitness f(xi)\n",
        "4. Return the best individual x* with max f(x)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š 6. Visualization (Simplified Example)\n",
        "\n",
        "Letâ€™s say we are optimizing:\n",
        "\n",
        "[\n",
        "f(x) = \\sin(x) + \\cos(2x)\n",
        "]\n",
        "\n",
        "GA steps:\n",
        "\n",
        "* Randomly initialize ( x \\in [0, 10] )\n",
        "* Evaluate ( f(x) )\n",
        "* Keep top solutions â†’ Crossover â†’ Mutate â†’ Repeat\n",
        "  â†’ Over generations, the population â€œmovesâ€ toward the region where ( f(x) ) is maximum.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¬ 7. Advantages of GA\n",
        "\n",
        "âœ… Works well with **nonlinear**, **discontinuous**, or **non-differentiable** functions.\n",
        "âœ… Doesnâ€™t require gradient information.\n",
        "âœ… Can escape local minima.\n",
        "âœ… Easy to parallelize (evaluate multiple solutions at once).\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ 8. Limitations\n",
        "\n",
        "âŒ Computationally expensive (evaluating each chromosomeâ€™s fitness repeatedly).\n",
        "âŒ Convergence can be slow.\n",
        "âŒ Sensitive to parameter tuning (population size, mutation rate).\n",
        "âŒ May overfit or oscillate if mutation/crossover rates are not balanced.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© 9. Example in Your Code Context\n",
        "\n",
        "Your **fitness function** used **Decision Tree accuracy** as a measure of â€œfitness.â€\n",
        "\n",
        "So the GA is **searching the best combination** of:\n",
        "\n",
        "* `max_depth`\n",
        "* `min_samples_split`\n",
        "\n",
        "that **maximizes**:\n",
        "[\n",
        "f(\\text{chromosome}) = \\text{Average Cross-Validation Accuracy}\n",
        "]\n",
        "\n",
        "After 10 generations, it found:\n",
        "\n",
        "```\n",
        "Best Hyperparameters: max_depth=3, min_samples_split=7\n",
        "Best Accuracy: 0.9733\n",
        "```\n",
        "\n",
        "Thatâ€™s your **fittest individual** â€” the â€œbest evolved species.â€\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  10. Summary Table\n",
        "\n",
        "| Concept     | Symbol / Example    | Meaning                                   |\n",
        "| ----------- | ------------------- | ----------------------------------------- |\n",
        "| Population  | ( P^{(t)} )         | All candidate solutions at generation *t* |\n",
        "| Chromosome  | [3, 7]              | Decision Tree hyperparameters             |\n",
        "| Gene        | 3 or 7              | A single value in chromosome              |\n",
        "| Fitness     | ( f(x_i) )          | Accuracy of the model                     |\n",
        "| Selection   | argmax(fitness)     | Pick top individuals                      |\n",
        "| Crossover   | combine(p1, p2)     | Mix parent genes                          |\n",
        "| Mutation    | random_change(gene) | Introduce diversity                       |\n",
        "| Termination | after N generations | Stop evolution                            |\n",
        "| Output      | Best fitness        | Optimal solution                          |\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
